{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gdal\n",
    "import ogr\n",
    "from skimage import exposure\n",
    "from skimage.segmentation import quickshift\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from PIL import Image\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bands 4 rows 1782 columns 3100\n",
      "(1782, 3100, 4)\n"
     ]
    }
   ],
   "source": [
    "driverTiff = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "## Open our dataset.\n",
    "wellington_waterfront = gdal.Open(\"wellington.tif\")\n",
    "\n",
    "## Our dataset contains more than one band of data so next we get the number of bands in the\n",
    "## raster using the RasterCount function.\n",
    "nbands = wellington_waterfront.RasterCount\n",
    "\n",
    "## Create an empty list.\n",
    "band_data = []\n",
    "print(\"bands\", wellington_waterfront.RasterCount, 'rows', wellington_waterfront.RasterYSize, 'columns', wellington_waterfront.RasterXSize)\n",
    "\n",
    "## Then append each raster band to that list.\n",
    "for i in range(1, nbands+1):\n",
    "    band = wellington_waterfront.GetRasterBand(i).ReadAsArray()\n",
    "    band_data.append(band)\n",
    "band_data = np.dstack(band_data)\n",
    "print(band_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gives an image where values are now between 0 and 1\n",
    "img = exposure.rescale_intensity(band_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quickshift Segmentation:\n",
    "## Parameters:\n",
    "## img - our input image.\n",
    "## ratio - balances color-space proximity and image-space proximity. Higher values give more weight to color-space. \n",
    "## Value has to be between 0 and 1. We chose 0.5 for an even balance between the two.\n",
    "## max_dist - cut-off point for data distances. Higher (we chose a value of 20) means fewer clusters.\n",
    "## convert2lab - whether the input should be converted to Lab colorspace prior to segmentation. \n",
    "\n",
    "segments = quickshift(img, ratio=0.5, max_dist=20, convert2lab=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(segments).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID for each Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the segment_features function below calculates descriptive statistics (mean, max, min, variance) for each band. \n",
    "## These are the values that are used by the random forests algorithm to classify the segments into land cover types.\n",
    "\n",
    "def segment_features(segment_pixels):\n",
    "    features = []\n",
    "    npixels, nbands = segment_pixels.shape\n",
    "    \n",
    "    for b in range(nbands):\n",
    "        stats = scipy.stats.describe(segment_pixels[:, b])\n",
    "        band_stats = list(stats.minmax) + list(stats)[2:]\n",
    "        if npixels == 1:\n",
    "            band_stats[3] = 0.0\n",
    "        features += band_stats\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are multiple cells that have the same number, this gets just the unique values and \n",
    "## groups the pixels by segment ID. \n",
    "segment_ids = np.unique(segments)\n",
    "\n",
    "## Save to empty list\n",
    "objects = []\n",
    "\n",
    "## Save the ID of each object\n",
    "object_ids = []\n",
    "\n",
    "## Loop through all segment IDs to get all the cells that occur within a given segment\n",
    "for id in segment_ids:\n",
    "    segment_pixels = img[segments == id]\n",
    "    object_features = segment_features(segment_pixels)\n",
    "    objects.append(object_features)\n",
    "    object_ids.append(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Segments to Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_fn = 'segments_final.tif'\n",
    "\n",
    "segments_ds = driverTiff.Create(segments_fn, wellington_waterfront.RasterXSize, wellington_waterfront.RasterYSize,\n",
    "                                1, gdal.GDT_Float32)\n",
    "segments_ds.SetGeoTransform(wellington_waterfront.GetGeoTransform())\n",
    "segments_ds.SetProjection(wellington_waterfront.GetProjectionRef())\n",
    "segments_ds.GetRasterBand(1).WriteArray(segments)\n",
    "segments_ds = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truth - Training and Test - Data (Points Generated in QGIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = wellington_waterfront.RasterYSize\n",
    "ncols = wellington_waterfront.RasterXSize\n",
    "\n",
    "## Read in truth data using geopandas \n",
    "## Create GeoDataFrame (gdf)\n",
    "gdf = gpd.read_file('truth_data2.shp')\n",
    "\n",
    "## Get names for classes\n",
    "class_names = gdf['LCtype'].unique()\n",
    "\n",
    "## Print to check the classes are correct\n",
    "print('class names', class_names)\n",
    "\n",
    "## Now have a class name that corresponds to a class ID\n",
    "## Create a unique id (integer) for each land cover class/label\n",
    "class_ids = np.arange(class_names.size) + 1\n",
    "print('class ids', class_ids)\n",
    "\n",
    "## Save a csv file that contains this table in it that relates each class name to a class ID\n",
    "df = pd.DataFrame({'label': class_names, 'id': class_ids})\n",
    "df.to_csv('class_lookup.csv')\n",
    "\n",
    "\n",
    "## Add a column into the shapefile that gives the ID number\n",
    "gdf['id'] = gdf['LCtype'].map(dict(zip(class_names, class_ids)))\n",
    "print('gdf with ids', gdf.head())\n",
    "\n",
    "\n",
    "## Split the truth data into training and test data sets and save each to a new shapefile\n",
    "gdf_train = gdf.sample(frac=0.7)  ## 70% of observations assigned to training data (30% to test data)\n",
    "gdf_test = gdf.drop(gdf_train.index)\n",
    "\n",
    "print('gdf shape', gdf.shape, 'training shape', gdf_train.shape, 'test. gdf_test.shape')\n",
    "\n",
    "gdf_train.to_file('train_data.shp')\n",
    "gdf_test.to_file('test_data.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasterize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read/open the training data shapefile creted in QGIS.\n",
    "train_ds = ogr.Open('train_data.shp')\n",
    "## Make training dataset a layer.\n",
    "lyr = train_ds.GetLayer()  \n",
    "\n",
    "\n",
    "## Create a new raster layer in memory, will allow use to make a new dataset\n",
    "driver = gdal.GetDriverByName('MEM') \n",
    "\n",
    "## New Gdal dataset of rasterised vectors.\n",
    "## Create(file name blank (as in memory), x number of columns, y number of columns, nuber of bands, data type)\n",
    "target_ds = driver.Create('', wellington_waterfront.RasterXSize, wellington_waterfront.RasterYSize, 1, gdal.GDT_UInt16)\n",
    "\n",
    "## Set geotransform - tells where is space this is located relative to projection.\n",
    "target_ds.SetGeoTransform(wellington_waterfront.GetGeoTransform())\n",
    "target_ds.SetProjection(wellington_waterfront.GetProjection())\n",
    "\n",
    "## Rasterize the training points\n",
    "## options - when do rasterization, label raster value corrosponding ID field.\n",
    "options = ['ATTRIBUTE=id']\n",
    "gdal.RasterizeLayer(target_ds, [1], lyr, options=options)\n",
    "\n",
    "## Retrieve the rasterized data and print basic stats. Check there are 5 classes.\n",
    "data = target_ds.GetRasterBand(1).ReadAsArray()\n",
    "print('Min =', data.min(), 'Max =', data.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Truth data used to train model, 2D array.\n",
    "\n",
    "ground_truth = target_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "## Get the values for each class, give unique values from ground truth.\n",
    "classes = np.unique(ground_truth)[1:]\n",
    "print('class values', classes)\n",
    "\n",
    "\n",
    "\n",
    "## Find which segments belong to which class, for each class (land cover type) record the associated segment IDs.\n",
    "## Which segments corrospond to which land cover type (i).\n",
    "segments_per_class = {}\n",
    "\n",
    "for i in classes:\n",
    "    segments_of_class = segments[ground_truth == i]\n",
    "    segments_per_class[i] = set(segments_of_class)\n",
    "    print(\"Training segments for class\", i, \":\", len(segments_of_class))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Final Classified Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New array of training image.\n",
    "train_img = np.copy(segments)\n",
    "## Find what the maximum segment value is.\n",
    "threshold = train_img.max() + 1  # make the threshold value greater than any land cover class value\n",
    "\n",
    "## Loop through classes, each class have a label that is greater than the maximum value in the\n",
    "## segmented image. Each segment assigned to ID. \n",
    "for klass in classes:\n",
    "    class_label = threshold + klass\n",
    "    for segment_id in segments_per_class[klass]:\n",
    "        train_img[train_img == segment_id] = class_label\n",
    "\n",
    "\n",
    "## Results in image where segments with no training data are classified as 0.\n",
    "## Segments with training data classified with class number.\n",
    "train_img[train_img <= threshold] = 0\n",
    "train_img[train_img > threshold] -= threshold\n",
    "        \n",
    "##  Create objects and labels for training data.\n",
    "training_objects = []\n",
    "training_labels = []\n",
    "\n",
    "## Find out is segment in the same dataset as class? \n",
    "for klass in classes:\n",
    "    class_train_object = [v for i, v in enumerate(objects) if segment_ids[i] in segments_per_class[klass]]\n",
    "    training_labels += [klass] * len(class_train_object)\n",
    "    training_objects += class_train_object\n",
    "        \n",
    "\n",
    "classifier = RandomForestClassifier(n_jobs=-1)  # setup random forest classifier\n",
    "classifier.fit(training_objects, training_labels)  # fit rf classifier\n",
    "print('Fitting Random Forest Classifier')\n",
    "predicted = classifier.predict(objects)  # predict with rf classifier\n",
    "print('Predicting Classifications')\n",
    "\n",
    "\n",
    "## Create numpy array from rf classification and save to raster\n",
    "clf = np.copy(segments)\n",
    "for segment_id, klass in zip(segment_ids, predicted):\n",
    "    clf[clf == segment_id] = klass\n",
    "    \n",
    "print('Prediction applied to')\n",
    "    \n",
    "## Give 2D array with the same number of rows and columns as the image.\n",
    "mask = np.sum(img, axis=2)  # this section masks no data values\n",
    "mask[mask > 0.0] = 1.0\n",
    "mask[mask == 0.0] = -1.0\n",
    "clf = np.multiply(clf, mask)\n",
    "clf[clf < 0] = -9999.0\n",
    "\n",
    "print('Saving class classification to raster')\n",
    "\n",
    "\n",
    "clfds = driverTiff.Create('classified_result1.tif', wellington_waterfront.RasterXSize, wellington_waterfront.RasterYSize,\n",
    "                          1, gdal.GDT_Float32)  # this section saves to raster\n",
    "clfds.SetGeoTransform(wellington_waterfront.GetGeoTransform())\n",
    "clfds.SetProjection(wellington_waterfront.GetProjection())\n",
    "clfds.GetRasterBand(1).SetNoDataValue(-9999.0)\n",
    "clfds.GetRasterBand(1).WriteArray(clf)\n",
    "clfds = None\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Photos/Quickshift.JPG') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
